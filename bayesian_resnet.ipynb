{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f232bb",
   "metadata": {
    "id": "d0f232bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 16:20:04.722445: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-30 16:20:04.722506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-30 16:20:04.722511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import jax\n",
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import distrax\n",
    "import jax.scipy.stats as stats\n",
    "import optax\n",
    "#from jax_resnet import ResNet18, pretrained_resnet\n",
    "from resnet import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5ad171",
   "metadata": {
    "id": "9c5ad171"
   },
   "outputs": [],
   "source": [
    "model=ResNet(num_classes= 10,\n",
    "               c_hidden= (16, 32, 64),\n",
    "               num_blocks= (3, 3, 3),\n",
    "               act_fn= nn.relu,\n",
    "               block_class= ResNetBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "SQAgbhWTqTLS",
   "metadata": {
    "id": "SQAgbhWTqTLS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jax.tree_util import tree_map\n",
    "from torch.utils import data\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "mean, std = [0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]\n",
    "\n",
    "def image_to_numpy(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = (img / 255. - mean) / std\n",
    "    return img\n",
    "\n",
    "test_transform = image_to_numpy\n",
    "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "    image_to_numpy\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uC41g7p5rrK1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uC41g7p5rrK1",
    "outputId": "c24b3f4a-e5c9-470a-e26f-226a60d14e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_dataset = CIFAR10('/tmp/cifar10/', download=True, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60e5d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_test = CIFAR10('/tmp/cifar10/', download=True, train=False, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c1d6f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_val = CIFAR10('/tmp/cifar10/', download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2a35d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "\n",
    "train_set, _ = torch.utils.data.random_split(cifar_dataset, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "_, val_set = torch.utils.data.random_split(cifar_val, [45000, 5000], generator=torch.Generator().manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79634fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "import os\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "# We need to stack the batch elements\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "    \n",
    "train_loader = data.DataLoader(train_set,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True,\n",
    "                               collate_fn=numpy_collate,\n",
    "                               num_workers=0,\n",
    "                               )\n",
    "val_loader   = data.DataLoader(val_set,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=numpy_collate,\n",
    "                               num_workers=0,\n",
    "                               )\n",
    "test_loader  = data.DataLoader(cifar_test,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=numpy_collate,\n",
    "                               num_workers=0,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd63618f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mean [0.27015958 0.20856956 0.12457092]\n",
      "Batch std [0.96578211 1.0372434  1.04271615]\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "print(\"Batch mean\", X.mean(axis=(0,1,2)))\n",
    "print(\"Batch std\", X.std(axis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b875b778-845a-45ed-8b76-f43f01cef524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59abfc8d",
   "metadata": {
    "id": "59abfc8d"
   },
   "outputs": [],
   "source": [
    "def log_prior(params):\n",
    "    return 1.\n",
    "\n",
    "def loglikelihood(params, batch_stats,batch,train=True):\n",
    "    X, y = batch\n",
    "    outs= model.apply({'params':params,'batch_stats':batch_stats}, \n",
    "                                         X,\n",
    "                                         train=train,\n",
    "                                         mutable=['batch_stats'] if train else False)\n",
    "    logits, new_model_state = outs if train else (outs, None)\n",
    "    dist=distrax.Categorical(logits=logits)\n",
    "    ll=jnp.mean(dist.log_prob(y))\n",
    "    return ll,new_model_state \n",
    "\n",
    "def log_posterior(params,batch_stats,batch):\n",
    "    nll,new_model_state=loglikelihood(params,batch_stats,batch)\n",
    "    return nll-log_prior(params),new_model_state\n",
    "\n",
    "@jit\n",
    "def acc_top1(params,stats,data_loader):\n",
    "    y_pred=list()\n",
    "    y_true=list()\n",
    "    for batch in enumerate(data_loader):\n",
    "        X, y = batch\n",
    "        X_batch=jnp.array(X)\n",
    "        y_batch=jnp.array(y)\n",
    "        prediction = model.apply({'params':params,'batch_stats':stats}, X_batch, train=False, mutable=False)\n",
    "        y_pred.append(jnp.argmax(prediction, axis=1))\n",
    "        y_true.append(y_batch)\n",
    "    y_pred=jnp.concatenate(y_pred)\n",
    "    y_true=jnp.concatenate(y_true)   \n",
    "    return jnp.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12ea58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "\n",
    "grad_log_post=jax.jit(jax.value_and_grad(log_posterior,has_aux=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb35fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(10)\n",
    "model_key, data_key = jax.random.split(key)\n",
    "variables = model.init(model_key, jnp.array(X),train=True)\n",
    "params, batch_stats = variables['params'], variables['batch_stats']\n",
    "ret,grads=grad_log_post(params,batch_stats,(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aef178c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "curdir = os.getcwd()\n",
    "ckpt_dir =os.path.join(curdir,'posterior_samples')\n",
    "\n",
    "if os.path.exists(ckpt_dir):\n",
    "    shutil.rmtree(ckpt_dir)  # Remove any existing checkpoints from the last notebook run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed521414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shernandez/quantized_sgmcmc/posterior_samples'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11bd6da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    }
   ],
   "source": [
    "from flax.training import orbax_utils\n",
    "import orbax\n",
    "\n",
    "ckpt = {'model': params, 'stats': batch_stats}\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "options = orbax.checkpoint.CheckpointManagerOptions(max_to_keep=10, create=True)\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(ckpt_dir, orbax_checkpointer, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c23bd2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import orbax.checkpoint as ocp\n",
    "\n",
    "\n",
    "def run_sgmcmc(key, Nsamples, init_fn, update, get_params,init_params,init_stats):\n",
    "    \"Run SGMCMC sampler and return the test accuracy list\"\n",
    "    loss = list()\n",
    "    samples=list()\n",
    "    params, batch_stats =init_params, init_stats\n",
    "    key, subkey = jax.random.split(key)\n",
    "    state = init_fn( params)\n",
    "    num_iter=1\n",
    "    for i in range(Nsamples):\n",
    "        for batch in train_loader:\n",
    "            key, subkey = jax.random.split(key)\n",
    "            print(batch[0].shape)\n",
    "            (nll,new_state),grads=grad_log_post(get_params(state),batch_stats,batch)\n",
    "            batch_stats=new_state['batch_stats']\n",
    "            state = update(num_iter, subkey, grads, state)\n",
    "            loss.append(nll)\n",
    "            position={'params':(get_params(state)),'batch_stats':batch_stats}\n",
    "            samples.append(position)\n",
    "            num_iter+=1\n",
    "        #if (i%(Nsamples//10)==0):\n",
    "            print('iteration {0}, loss {1:.2f}'.format(i,loss[-1]))\n",
    "        #if (i%(Nsamples//10)==0):\n",
    "        #    logits=model.apply({'params':params,'batch_stats':batch_stats},X_batch,train=False,mutable=False)\n",
    "        #    accuracy = (logits.argmax(axis=-1) == y_batch).mean()\n",
    "        #    nll,_=loglikelihood(params,batch_stats,(X_batch,y_batch),train=False)\n",
    "        #    print('Epoch {0}, Log-likelihood : {1:8.2f}, Accuracy {2:8.2f}: '.format(j,nll,accuracy))\n",
    "    return samples,loss\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e487d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgmcmcjax.diffusions import sgld\n",
    "\n",
    "learning_rate=1e-5\n",
    "n_epochs=100\n",
    "key = jax.random.PRNGKey(10)\n",
    "init_fn, update, get_params = sgld(1e-5)\n",
    "update = jit(update)\n",
    "\n",
    "key = jax.random.PRNGKey(10)\n",
    "model_key, data_key = jax.random.split(key)\n",
    "variables = model.init(model_key, jnp.array(X),train=True)\n",
    "params, batch_stats = variables['params'], variables['batch_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9697fe1-7b3f-4c41-873a-926e53803dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 16:27:46.773483: W external/xla/xla/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 13.18MiB (rounded to 13816320)requested by op \n",
      "2025-01-30 16:27:47.326498: W external/xla/xla/tsl/framework/bfc_allocator.cc:494] ****************************************************************************************************\n",
      "E0130 16:27:47.326576 3886244 pjrt_stream_executor_client.cc:2985] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 13816248 bytes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 13816248 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_sgmcmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m, in \u001b[0;36mrun_sgmcmc\u001b[0;34m(key, Nsamples, init_fn, update, get_params, init_params, init_stats)\u001b[0m\n\u001b[1;32m     15\u001b[0m key, subkey \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 17\u001b[0m (nll,new_state),grads\u001b[38;5;241m=\u001b[39m\u001b[43mgrad_log_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m batch_stats\u001b[38;5;241m=\u001b[39mnew_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_stats\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m state \u001b[38;5;241m=\u001b[39m update(num_iter, subkey, grads, state)\n",
      "\u001b[0;31mValueError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 13816248 bytes."
     ]
    }
   ],
   "source": [
    "run_sgmcmc(key,n_epochs,init_fn,update,get_params,params,batch_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01975bc-8ef5-4fc8-897f-f5f9decd0dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "044d01caf2964c508425c196aaf2fcc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2025a435121d4a67a2f85c44e173e802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9bcbd68636954475975fd563aadd12ff",
       "IPY_MODEL_7fa4276e512f49e988b9bc1c86b76279",
       "IPY_MODEL_532766948eda430e905b4bc99bddf04f"
      ],
      "layout": "IPY_MODEL_e2520f5450b64213942f5a4c1e645330"
     }
    },
    "231ebde50b85432ea3760856a6bb5158": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "494bda50ca494b79a9d927d0ce41b4c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "530cadab3336471aacab3635cce60793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "532766948eda430e905b4bc99bddf04f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_494bda50ca494b79a9d927d0ce41b4c9",
      "placeholder": "​",
      "style": "IPY_MODEL_231ebde50b85432ea3760856a6bb5158",
      "value": " 0/1000 [00:10&lt;?, ?it/s]"
     }
    },
    "6fffdccd5e9f44cfa0de6c56a4896cad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fa4276e512f49e988b9bc1c86b76279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_044d01caf2964c508425c196aaf2fcc1",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_530cadab3336471aacab3635cce60793",
      "value": 0
     }
    },
    "9bcbd68636954475975fd563aadd12ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0732fd9a6db4397ad8eaa6897a9c0a4",
      "placeholder": "​",
      "style": "IPY_MODEL_6fffdccd5e9f44cfa0de6c56a4896cad",
      "value": "  0%"
     }
    },
    "b0732fd9a6db4397ad8eaa6897a9c0a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2520f5450b64213942f5a4c1e645330": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
